### Hi there ðŸ‘‹

I'm Tianheng Cheng, pursuing my Ph.D. now and working on Computer Vision and Machine Intelligence.

My research goal is to enable machines/robots to **see** and **understand** the world.

Previous works/publications are listed at [Google Scholar ðŸ“š](https://scholar.google.com/citations?user=PH8rJHYAAAAJ).

Currently, I'm devoted to research on **visual-language modeling** and **multimodal models**. Before that, I mainly focused on fundamental tasks such as **object detection** and **instance segmentation**, as well as visual perception for autonomous driving.

**Highlighted Works of those pinned works:**

* The latest works ðŸ”¥: [YOLO-World (CVPR 2024)](https://github.com/AILab-CVC/YOLO-World) for real-time open-vocabulary object detection; [Symphonies (CVPR 2024)](https://github.com/hustvl/Symphonies) for camera-based 3D scene completion.
* [SparseInst (CVPR 2022)](https://github.com/hustvl/SparseInst) aims for real-time instance segmentation with a simple fully convolutional framework! [MobileInst (AAAI 2024)](https://ojs.aaai.org/index.php/AAAI/article/view/28555) further explores temporal consistency and kernel reuse for efficient mobile video instance segmentation.
* [BoxTeacher (CVPR 2023)](https://github.com/hustvl/BoxTeacher) bridges the gap between fully supervised and box-supervised instance segmentation. With ~1/10 annotation cost, BoxTeacher can achieve 93% performance versus fully supervised methods.
* [BMask R-CNN (ECCV 2020)](https://github.com/hustvl/BMaskR-CNN) is the first work to introduce boundary modeling for objects and aims for high-performance instance segmentation. It leads the research about object boundaries for instance segmentation.
* [GKT (arXiv)](https://github.com/hustvl/GKT) addresses the ill-posed 2D-to-3D (Surrounding views to Bird-Eye views) transformation with the concern about accuracy and speed, especially for practical implementation for autonomous systems.
